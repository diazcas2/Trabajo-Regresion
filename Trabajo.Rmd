---
title: "Trabajo"
author: "María de los Ángeles Díaz Castro, Álvaro Nieva Valenzuela"
date: "2025-12-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Librerías
```{r}

pacman::p_load(
  openxlsx, ggplot2, dplyr,
  car, lmtest, MASS, sandwich, corrplot,leaps
)

```

# Importación de los datos
```{r}
datos <- read.xlsx("boston.xlsx")
```

# Ejercicio 1
**Considera la variable respuesta crim relacionándola con la variable X con la que tenga mayor relación lineal.**

Para ver que variables están más relacionadas con crim, hacemos la correlación de Pearson. De manera que debemos fijarnos solo en la columna de crim que indica las relaciones con esta variable.
```{r}
matcorr <- cor(datos, method = "pearson")
corrplot(matcorr, method = "number", tl.col = "black")
```
Podemos ver que las variables más relacionadas con crim son indus,nox, lstat. Por otro lado, las que menos relacionadas están son black y chas. Como nos preguntan por la que más, trabajaremos con lstat que tiene una correlación alta con crim.

**1. Evalúa el efecto de X sobre crim, gráficamente y numéricamente. Es decir, indica como es la relación (fuerza y tipo).**

```{r}
modelo<-lm(crim~lstat,data = datos)

plot(datos$lstat, datos$crim,
     col = "blue",
     xlab = "Porcentaje de población con bajo nivel socioeconómico (lstat)",
     ylab = "Tasa de crimen (crim)",
     main = "Relación entre lstat y crim")               

abline(modelo, col = "red", lwd = 2)
```


Para medir la fuerza y dirección del modelo, simplemente vamos a ver que ocurre con su correlación de Pearson, aunque con anterioridad vimos que estaban bastante relacionadas.

```{r}
cor(datos$crim, datos$lstat, method = "pearson")
```

La correlación obtenida es bastante alta y va en sentido positivo.

**2. Obtén la recta de mínimos cuadrados. Interpreta los resultados obtenidos (coeficientes, significatividad, R2, contraste del modelo, etc...).**

La recta de mínimos cuadrados fue hallada en el apartado anterior y la llamamos modelo. A continuación, vamos a ver que parámetros tiene dicha recta.
```{r}
coef<-coef(modelo)
names(coef)<-paste0('beta_',c(0,1))
coef
```
De esta forma, la recta tiene la siguiente exppresión: $y=0.4283435\cdot x-2.6230522 $. Al ser la pendiente positiva, sabemos que a mayor porcentaje de población con bajo nivel socioeconómico (lstat), mayor es la tasa de crimen.

Por otro lado, para representar los resultados aplicamos summary:

```{r}
summary(modelo)
```

El modelo explica aproximadamente el 41% de la variabilidad de crim (R² = 0.4085; R² ajustado = 0.4055), indicando que lstat es un predictor relevante de la tasa de crimen. La desviación típica de los residuos es 3.4, lo que significa que las predicciones se desvían en promedio ±3.4 unidades. La relación entre lstat y crim es lineal y positiva, y la pendiente es altamente significativa (p < 2e-16), confirmando que el efecto de lstat es estadísticamente confiable. Además, el contraste F global (p < 2.2e-16) respalda que el modelo en su conjunto es significativo. Los residuos están centrados alrededor de 0, aunque existen algunos valores extremos que podrían considerarse outliers. Realmente, aunque la pendiente es significativa y la relación es positiva, el modelo solo explica ~41% de la variabilidad, por lo que otros factores además de lstat influyen en la tasa de crimen.

**3. Dibuja el diagrama de dispersión, la recta de regresión y las bandas de confianza al 90 %.**

```{r}
# Para poder usar predict, necesitamos crear un rango de valores de lstat para predecir.
nuevos <- data.frame(lstat = seq(min(datos$lstat), max(datos$lstat), length.out = 100))
pred <- predict(modelo, newdata = nuevos, interval = "confidence", level = 0.90)
bandas_est <- predict(modelo, newdata = nuevos, interval = "confidence", level = 0.90)

plot(datos$lstat, datos$crim,
     col = "blue",
     xlab = "Porcentaje de población con bajo nivel socioeconómico (lstat)",
     ylab = "Tasa de crimen (crim)",
     main = "Relación entre lstat y crim")               

abline(modelo, col = "red", lwd = 2)
lines(nuevos$lstat, bandas_est[,2], col = 'black', lty = 1, lwd = 1)
lines(nuevos$lstat, bandas_est[,3], col = 'black', lty = 1, lwd = 1)

# Leyenda opcional
legend("topleft", legend = c("Observaciones", "Recta de regresión", "Bandas de confianza 90%"),
       col = c("blue", "red", "black"), pch = c(19, NA, NA), lty = c(NA,1,1), lwd = 1)

```

**4. Realiza un diagnóstico de los residuos. Si falla algunas de las condiciones, busca una (o varias) posible solución.**

```{r}
# diagnóstico linealidad y homocedasticidad de los residuos
residuos <- residuals(modelo)
predichos <- fitted.values(modelo)
par(mfcol=c(1,2))
plot(predichos,residuos, col='BLUE',main = 'Gráfica de residuos')
abline(h=0,lty=2)

# diagnóstico normalidad residuos
qqnorm(residuos, col='BLUE')
qqline(residuos)
shapiro.test(residuos)
```

A continuación, interpretemos las gráficas. Por un lado, la gráfica de residuos frente a los valores ajustados muestra un patrón descendente, donde los residuos tienden a ser negativos a medida que aumentan los valores ajustados. Lo que indica que la relación no es completamente lineal y que la variabilidad de los residuos no es constante, por lo que la condición de homocedasticidad tampoco se cumple totalmente. Por otro lado, del Q-Q plot podemos ver que los residuos se alejan de la línea recta en los extremos, sugiriendo colas más largas de lo esperado. Sin embargo, si nos fijamos en el test de Shapiro-Wilk, no nos sorprende el resultado de W = 0.82896 y p-value = 4.984e-14. Ya que nos indican que los residuos no son normales. De esta forma, podríamos pensar que hay posibles outliers o puntos extremos que están afectando la normalidad y la dispersión.

Podríamos considerar distintas soluciones como Verificar si hay outliers extremos y decidir si deben eliminarse o analizarse aparte o bien considerar un modelo no lineal, lo que tendr´´ia mucho sentido por lo que vimos en las gráficas. Otra opción podría ser incluir otras variables predictoras.

# Ejercicio 2
**Considera la variable respuesta crim relacionándola con el predictor medv.**
**1. Evalúa el efecto de medv sobre crim.**

```{r}
summary(datos[, c("crim","medv")])

# Obtenemos el gráfico de dispersión + tendencia
ggplot(datos, aes(x = medv, y = crim)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "crim vs medv", x = "medv (valor mediano vivienda)", y = "crim (tasa criminalidad)")

# Obtenemos la correlación de Pearson
pearson_corr<-cor(datos$medv, datos$crim, method = "pearson")

# Obtenemos la correlación de Spearman
spearman_corr<-cor(datos$medv, datos$crim, method = "spearman")

cat("Correlación de Pearson: ",pearson_corr)
cat("Correlación de Spearman: ",spearman_corr)

```

El resumen descriptivo indica que `crim` presenta una distribución claramente asimétrica a la derecha: la mayoría de observaciones toman valores bajos (mediana ≈ 0.241), pero existen valores extremos elevados (máximo ≈ 24.39). Mientras que `medv` se concentra alrededor de 20–31 (mediana ≈ 23.90) y alcanza un máximo de 50, lo que sugiere un rango acotado en el extremo superior.

El diagrama de dispersión muestra una tendencia decreciente es decir, que a medida que aumenta `medv`, tiende a disminuir `crim`. También se observa que para valores bajos de `medv` hay mucha más variabilidad en `crim`, mientras que para valores altos de `medv` la criminalidad se mantiene cercana a cero y con poca dispersión. Esto sugiere la presencia de posibles valores atípicos y un patrón compatible con heterocedasticidad (varianza no constante).

Numéricamente, la correlación de Pearson es r = −0.523, lo que indica una asociación lineal negativa moderada entre ambas variables: barrios con mayor `medv` tienden a presentar menor `crim`. La correlación de Spearman es ρ = −0.515, muy cercana a Pearson, lo que refuerza que la relación es también monótona decreciente y que el resultado no depende exclusivamente de la linealidad estricta.

**2. Obtén la recta de mínimos cuadrados. Interpreta los resultados obtenidos (coeficientes, significatividad,R2, contraste del modelo, etc...).**

```{r}
#Ajustamos el modelo lineal
m1 <- lm(crim ~ medv, data = datos)
summary(m1)
```
- Coeficientes e interpretación:
  - El intercepto, con valor de 8.5183 (valor medio estimado de `crim` cuando `medv = 0`), aun siendo estadísticamente significativo, su interpretación práctica es limitada porque medv = 0 no es un valor realista en el contexto del conjunto de datos.
  - La pendiente de `medv` (−0.2550) indica que, manteniendo lo demás constante (aquí no hay más variables), un aumento de 1 unidad en `medv` se asocia con una disminución media de 0.255 unidades en `crim`.
  
- Significatividad:
  - El coeficiente de `medv` es altamente significativo (t = −8.615, p = 2.26e−15). Por tanto, existe evidencia estadística muy fuerte para rechazar la hipótesis nula y afirmar que `medv` tiene un efecto lineal distinto de cero sobre crim.
  
- Bondad de ajuste (R^2):
  - La bondad de ajuste cuenta con un valor de 0.2736, lo que significa que aproximadamente un 27.4% de la variabilidad observada en `crim`.

- Contraste global del modelo (F):
  - El contraste global del modelo es significativo, siendo de: F = 74.21 con (1, 197) grados de libertad y p = 2.258e−15. Esto confirma que el modelo con `medv` como predictor mejora de forma significativa frente al modelo nulo (solo intercepto). En regresión simple, este contraste es coherente con el contraste de la pendiente.

- Error estándar residual:
  - El error estándar residual es 3.769, que comparado con la escala de `crim` (con máximos altos y mucha asimetría), sugiere que hay dispersión considerable alrededor de la recta, consistente con el R^2 moderado y con la presencia probable de valores extremos.
  
**3. Dibuja el diagrama de dispersión, la recta de regresión y las bandas de predicción al 90 %.**

```{r}
# Rejilla de valores de medv en el rango observado
grid <- data.frame(medv = seq(min(datos$medv), max(datos$medv), length.out = 200))

pred90 <- predict(m1, newdata = grid, interval = "prediction", level = 0.90)
pred90 <- cbind(grid, pred90)

# Gráfico
ggplot(datos, aes(medv, crim)) +
  geom_point() +
  geom_line(data = pred90, aes(y = fit)) +
  geom_line(data = pred90, aes(y = lwr), linetype = 2) +
  geom_line(data = pred90, aes(y = upr), linetype = 2) +
  labs(title = "Recta de regresión y bandas de predicción (90%)",
       x = "medv", y = "crim")
```

**4. Realiza un análisis de los residuos.**

```{r}
#Realizamos las comprobaciones típicas con gráficos y tests

#Gráficos estándar del modelo
par(mfrow = c(2,2))
plot(m1)
par(mfrow = c(1,1))

# Normalidad (Shapiro-Wilk)
shapiro.test(residuals(m1))

```
A partir de los gráficos de diagnóstico del modelo m1 se observa que los residuos no se comportan como una nube aleatoria alrededor de 0 en el gráfico *Residuals vs Fitted*, sino que muestran un patrón y, además, una dispersión creciente para valores ajustados altos. Esto sugiere que el supuesto de homocedasticidad (varianza constante) no se cumple adecuadamente.

En el gráfico *Q–Q Residuals* los puntos se separan claramente de la recta teórica, especialmente en las colas, lo que indica que los residuos no siguen una distribución normal. Esta falta de normalidad queda confirmada por el test de *Shapiro–Wilk*, con W = 0.74068 y p-valor < 2.2·10^(-16), por lo que se rechaza la hipótesis de normalidad de los residuos.

Finalmente, en *Residuals vs Leverage* aparecen algunas observaciones destacadas, es decir, con residuo grande y/o mayor leverage, lo que sugiere la presencia de posibles puntos atípicos o influyentes que podrían estar afectando al ajuste.

En conjunto, el diagnóstico indica que el modelo lineal simple es útil para describir la tendencia global entre `medv` y `crim`, pero no cumple bien los supuestos de normalidad y varianza constante, por lo que conviene considerar una alternativa en el siguiente apartado (por ejemplo, una transformación de `crim`).

**5. ¿Te parece adecuado haber realizado regresión lineal o es preferible otro tipo de regresión?. Ajusta el modelo que te parezca más adecuado.**

En el modelo m1, el análisis de residuos mostraba heterocedasticidad (varianza creciente) y no normalidad marcada, además de posibles observaciones problemáticas. Por tanto, aunque el modelo lineal capta una tendencia media decreciente, no resulta el más adecuado si queremos que los supuestos del modelo lineal (normalidad y varianza constante de los errores) se cumplan razonablemente.

Dado que `crim` es una variable positiva y muy asimétrica, una alternativa estándar es transformar la respuesta con logaritmos y ajustar:
\[
m_2:\ \log(\texttt{crim}) = \beta_0 + \beta_1\,\texttt{medv} + \varepsilon
\]

```{r}
m2 <- lm(log(crim) ~ medv, data = datos)
summary(m2)

# Diagnóstico de residuos del nuevo modelo
par(mfrow = c(2,2))
plot(m2)
par(mfrow = c(1,1))

AIC(m1, m2)
```
- El R^2 de m2 es 0.2859, ligeramente mayor que en m1 (0.2736), lo que indica una mejora moderada en variabilidad explicada, además de una mejora más importante en el comportamiento de residuos.

- En los gráficos de diagnóstico de m2 se observa una mejor estabilización de la varianza (Scale–Location más plano) y una mejor aproximación a la normalidad en el Q–Q (aunque aún puede haber desviaciones en colas, habituales en datos con extremos).

- El AIC disminuye notablemente (de 1096.79 a 747.26), lo que apoya que el modelo transformado se ajusta mejor.

Como conclusión llegamos a que es preferible el modelo con transformación logarítmica m2, ya que mantiene un efecto significativo de medv sobre crim y mejora sustancialmente los problemas de heterocedasticidad y normalidad observados en m1.

# Ejercicio 3

**1. Encuentra el número óptimo de variables a incluir en un modelo predictivo de crim, según los criterios R2, BIC y CP, utilizando la metodología RegSubsets. Indica brevemente en que consiste esta metodología.**
**¿Qué variables incluye el modelo obtenido? (Seleccionar el criterio que más os guste). Interpreta los coeficientes obtenidos. ¿Tienen todas sentido?. ¿Son significativos?.**

La función RegSubsets del paquete leaps  compara de forma exhaustiva todos los subconjuntos posibles de predictores y selecciona, para cada tamaño, el mejor modelo. Después podemos elegir el modelo óptimo según un criterio (BIC, Cp, R² ajustado). Veámoslo:

```{r}
modelos <- regsubsets(crim ~ ., data = datos, nbest = 1)
res<- summary(modelos)
cat('Si utilizamos como criterio el R2, el número de componentes debe ser de ',which.max(res$adjr2))
cat('Si utilizamos como criterio el BIC, el número de componentes debe ser de ',which.min(res$bic))
cat('Si utilizamos como criterio el CP, el número de componentes debe ser de ',which.min(res$cp))

res
```
Viendo el summary, podemos decir que si nos basamos en el R2 o CP el modelo debería de incluir todas las variables. Sin embargo, si nos basamos en el BIC, el modelo estaría formado por las variables lstat,prtratio,nox,rm,chas que son las 5 más influyentes. 

En nuestro caso vamos a elegir el modelo elegido por el BIC.

```{r}
modeloBIC<-lm(crim~lstat+ptratio+nox+rm+chas,data=datos)
summary(modeloBIC)
```
Al analizar los coeficientes del modelo seleccionado por BIC, observamos que todas las variables incluidas son estadísticamente significativas (p < 0.001). Además, los predictores lstat, ptratio y nox presentan efectos positivos sobre la tasa de criminalidad, lo cual es coherente con la interpretación socioeconómica del conjunto de datos. La variable rm muestra un coeficiente positivo aunque en teoría debería relacionarse negativamente con el crimen, esto podría deberse a la colinealidad entre predictores. Por último, chas tiene signo negativo, lo que significa que hay menos criminalidad en zonas cercanas al río. Así, el modelo alcanza un R2 ajustado del 0.557, lo que indica un nivel de explicación moderado de la variabilidad de crimen.

**2. Selecciona el mejor modelo con el método stepwise. Indica brevemente en que consiste esta metodología y contesta a las siguientes preguntas:**
**¿Qué modelo piensas que es mejor? (Entre este y el/los obtenido/s mediante Regsubsets). ¿Qué% de la varianza de crim explica el modelo?¿Cuál es el efecto de la variable chas sobre crim?**

El método stepwise es una técnica de selección de variables que va construyendo el modelo añadiendo o eliminando variables paso a paso. En cada iteración evalúa si el añadir o eliminar variables mejora el modelo según un criterio (normalmente AIC). Veámoslo:

```{r}
modelocompleto <- lm(crim ~ ., data = datos)
stepwise <- step(modelocompleto, direction = "both")

summary(stepwise)
```

Si interpretamos los resultados utilizando el método stepwise en dirección ‘both’, podemos ver que usando el AIC va eliminando paso a paso las variables que menos aportan al modelo. En nuestro caso, primero se elimina la variable black y luego nox, de forma que el modelo final incluye las variables indus, chas, rm, age, dis, ptratio, lstat y medv. La mayoría de predictores resultan altamente significativos, excepto age. Este modelo presenta un R2 ajustado de 0.586, indicando un ajuste moderado, y un AIC inferior al modelo completo.

De esta forma, basándonos en el R2 ajustado, el mejor modelo es el de stepwise que explica un poco mejor la proporción de la variabilidad de crim, siendo de aproximadamente el 59%. 

Por otro lado, la variable chas tiene un efecto negativo y significativo sobre la criminalidad. Estar junto al río Charles reduce la tasa de criminalidad en aproximadamente 2.24 unidades, manteniendo constantes el resto de predictores. Esto tiene sentido, porque si buscamos que hay alrededor del río Charles podemos ver que esas áreas suelen ser más residenciales, más caras y de mayor nivel socioeconómico, lo que suele traducirse en menor criminalidad.

**3. Con el modelo obtenido con stepwise, realiza el diagnóstico de tu modelo, sin emprender ninguna acción, e indica los problemas que presenta.**

```{r}
par(mfrow = c(2,2))
plot(stepwise)
par(mfrow = c(1,1))

shapiro.test(residuals(stepwise))
```
Con lo obtenido en el diagnóstico, se pueden observar tres problemas principales: La heterocedasticidad, la no normalidad entre residuos y observaciones influyentes o alto leverage. Además se puede observar indicios de falta de linealidad en una parte del rango.

- Residuals vs Fitted:
  - La línea roja (suavizado) cae y sube. Con esto se puede considerarque la relación entre la respuesta y el conjunto de predictores no queda capturada de forma perfectamente lineal.
  - También se puede apreciar que para valores ajustados grandes la dispersión de residuos aumenta y aparecen varios residuos positivos grandes (puntos etiquetados), esto se relaciona con heterocedasticidad y outliers.
  
- Scale–Location
  - La línea roja no es horizontal y la dispersión no es uniforme. Esto indica que la varianza de los residuos no es constante a lo largo de los valores ajustados.
  
- Q–Q Residuals y Shapiro–Wilk
  - En el Q–Q plot los puntos se separan de la recta en la cola superior y algo en la inferior, lo que indica colas más pesadas que la normal y/o asimetría.
  
- Residuals vs Leverage
  - Aparecen observaciones con leverage alto. El hecho de tener leverage tan elevado implica que esas observaciones pueden condicionar el ajuste y los coeficientes.

El diagnóstico del modelo muestra que el ajuste lineal presenta heterocedasticidad (varianza no constante), no normalidad de los residuos (Shapiro–Wilk: p = 1.452e−12), y presencia de observaciones con leverage alto que podrían ser influyentes. Además, el patrón en Residuals vs Fitted sugiere que la relación no queda totalmente explicada mediante un esquema lineal.


**4. Emprende ahora las acciones que te parezcan oportunas e indica los problemas que has conseguido solucionar o mejorar un poco.**

```{r}
# Modelo completo en escala log
full_log <- lm(log(crim) ~ ., data = datos)

# Stepwise (AIC) en escala log
step_log <- step(full_log, direction = "both", trace = 0)

summary(step_log)
```
Se ha transformado la respuesta a log(`crim`), lo que hace que la varianza se estabilice y acerca los residuos a la normalidad.

```{r}
par(mfrow = c(2,2))
plot(step_log)
par(mfrow = c(1,1))

shapiro.test(residuals(step_log))
```
El nuevo modelo (step_log) mejora de forma clara el comportamiento de los residuos. En particular, la normalidad queda prácticamente solucionada: el test de Shapiro–Wilk da W=0.99206 y p=0.3517, por lo que no hay evidencia para rechazar normalidad, y el Q–Q plot se alinea mucho mejor con la recta teórica. Además, el gráfico Scale–Location muestra una dispersión más uniforme, lo que indica una reducción importante de la heterocedasticidad respecto al modelo anterior. En Residuals vs Fitted se aprecia también un patrón menos acusado, sugiriendo una mejora parcial de la linealidad. Por último, aunque en Residuals vs Leverage aún aparecen algunas observaciones con leverage relativamente alto, su impacto parece menor y el ajuste global es más estable.

**5. Obtén la predicción de la tasa de criminalidad para un barrio en la mediana de los predictores en el modelo escogido. Notar que las variables categóricas se tratan de diferente manera, no hay mediana.**

```{r}
# Variables que usa el modelo (sin la respuesta)
vars <- all.vars(formula(step_log))[-1]

# Construimos un "barrio típico": mediana en numéricas y moda en factores
new_med <- lapply(vars, function(v){
  x <- datos[[v]]
  if (is.numeric(x)) {
    median(x, na.rm = TRUE)
  } else if (is.factor(x)) {
    names(sort(table(x), decreasing = TRUE))[1]  # moda
  } else {
    names(sort(table(x), decreasing = TRUE))[1]
  }
})

new_med <- as.data.frame(new_med)
names(new_med) <- vars

new_med

```

```{r}
# Predicción puntual en escala log(crim)
pred_log <- predict(step_log, newdata = new_med)

# Predicción puntual en escala original crim
pred_crim <- exp(pred_log)

pred_crim
```
Para obtener la predicción de la tasa de criminalidad de un “barrio típico”, se construye un vector de predictores fijando la mediana en todas las variables numéricas incluidas en el modelo final `step_log`. En el caso de variables categóricas, como chas, no existe mediana; por ello se fija una categoría concreta, tomando como criterio la más frecuente en la muestra (moda). Con ese newdata se calcula la predicción mediante predict().

Debido a que el modelo está ajustado en la escala log(crim) la predicción se obtiene inicialmente en esa escala y posteriormente se transforma a la escala original aplicando la exponencial log(crim)=exp(log(crim)).
