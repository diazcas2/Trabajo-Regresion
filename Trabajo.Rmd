---
title: "Trabajo"
author: "María de los Ángeles Díaz Castro, Álvaro Nieva Valenzuela"
date: "2025-12-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Librerías
```{r}
library(openxlsx)
library(corrplot)
library(leaps)
```

# Importación de los datos
```{r}
datos <- read.xlsx("boston.xlsx")
```

# Ejercicio 1
**Considera la variable respuesta crim relacionándola con la variable X con la que tenga mayor relación lineal.**

Para ver que variables están más relacionadas con crim, hacemos la correlación de Pearson. De manera que debemos fijarnos solo en la columna de crim que indica las relaciones con esta variable.
```{r}
matcorr <- cor(datos, method = "pearson")
corrplot(matcorr, method = "number", tl.col = "black")
```
Podemos ver que las variables más relacionadas con crim son indus,nox, lstat. Por otro lado, las que menos relacionadas están son black y chas. Como nos preguntan por la que más, trabajaremos con lstat que tiene una correlación alta con crim.

**1. Evalúa el efecto de X sobre crim, gráficamente y numéricamente. Es decir, indica como es la relación (fuerza y tipo).**

```{r}
modelo<-lm(crim~lstat,data = datos)

plot(datos$lstat, datos$crim,
     col = "blue",
     xlab = "Porcentaje de población con bajo nivel socioeconómico (lstat)",
     ylab = "Tasa de crimen (crim)",
     main = "Relación entre lstat y crim")               

abline(modelo, col = "red", lwd = 2)
```


Para medir la fuerza y dirección del modelo, simplemente vamos a ver que ocurre con su correlación de Pearson, aunque con anterioridad vimos que estaban bastante relacionadas.

```{r}
cor(datos$crim, datos$lstat, method = "pearson")
```

La correlación obtenida es bastante alta y va en sentido positivo.

**2. Obtén la recta de mínimos cuadrados. Interpreta los resultados obtenidos (coeficientes, significatividad, R2, contraste del modelo, etc...).**

La recta de mínimos cuadrados fue hallada en el apartado anterior y la llamamos modelo. A continuación, vamos a ver que parámetros tiene dicha recta.
```{r}
coef<-coef(modelo)
names(coef)<-paste0('beta_',c(0,1))
coef
```
De esta forma, la recta tiene la siguiente exppresión: $y=0.4283435\cdot x-2.6230522 $. Al ser la pendiente positiva, sabemos que a mayor porcentaje de población con bajo nivel socioeconómico (lstat), mayor es la tasa de crimen.

Por otro lado, para representar los resultados aplicamos summary:

```{r}
summary(modelo)
```

El modelo explica aproximadamente el 41% de la variabilidad de crim (R² = 0.4085; R² ajustado = 0.4055), indicando que lstat es un predictor relevante de la tasa de crimen. La desviación típica de los residuos es 3.4, lo que significa que las predicciones se desvían en promedio ±3.4 unidades. La relación entre lstat y crim es lineal y positiva, y la pendiente es altamente significativa (p < 2e-16), confirmando que el efecto de lstat es estadísticamente confiable. Además, el contraste F global (p < 2.2e-16) respalda que el modelo en su conjunto es significativo. Los residuos están centrados alrededor de 0, aunque existen algunos valores extremos que podrían considerarse outliers. Realmente, aunque la pendiente es significativa y la relación es positiva, el modelo solo explica ~41% de la variabilidad, por lo que otros factores además de lstat influyen en la tasa de crimen.

**3. Dibuja el diagrama de dispersión, la recta de regresión y las bandas de confianza al 90 %.**

```{r}
# Para poder usar predict, necesitamos crear un rango de valores de lstat para predecir.
nuevos <- data.frame(lstat = seq(min(datos$lstat), max(datos$lstat), length.out = 100))
pred <- predict(modelo, newdata = nuevos, interval = "confidence", level = 0.90)
bandas_est <- predict(modelo, newdata = nuevos, interval = "confidence", level = 0.90)

plot(datos$lstat, datos$crim,
     col = "blue",
     xlab = "Porcentaje de población con bajo nivel socioeconómico (lstat)",
     ylab = "Tasa de crimen (crim)",
     main = "Relación entre lstat y crim")               

abline(modelo, col = "red", lwd = 2)
lines(nuevos$lstat, bandas_est[,2], col = 'black', lty = 1, lwd = 1)
lines(nuevos$lstat, bandas_est[,3], col = 'black', lty = 1, lwd = 1)

# Leyenda opcional
legend("topleft", legend = c("Observaciones", "Recta de regresión", "Bandas de confianza 90%"),
       col = c("blue", "red", "black"), pch = c(19, NA, NA), lty = c(NA,1,1), lwd = 1)

```

**4. Realiza un diagnóstico de los residuos. Si falla algunas de las condiciones, busca una (o varias) posible solución.**

```{r}
# diagnóstico linealidad y homocedasticidad de los residuos
residuos <- residuals(modelo)
predichos <- fitted.values(modelo)
par(mfcol=c(1,2))
plot(predichos,residuos, col='BLUE',main = 'Gráfica de residuos')
abline(h=0,lty=2)

# diagnóstico normalidad residuos
qqnorm(residuos, col='BLUE')
qqline(residuos)
shapiro.test(residuos)
```

A continuación, interpretemos las gráficas. Por un lado, la gráfica de residuos frente a los valores ajustados muestra un patrón descendente, donde los residuos tienden a ser negativos a medida que aumentan los valores ajustados. Lo que indica que la relación no es completamente lineal y que la variabilidad de los residuos no es constante, por lo que la condición de homocedasticidad tampoco se cumple totalmente. Por otro lado, del Q-Q plot podemos ver que los residuos se alejan de la línea recta en los extremos, sugiriendo colas más largas de lo esperado. Sin embargo, si nos fijamos en el test de Shapiro-Wilk, no nos sorprende el resultado de W = 0.82896 y p-value = 4.984e-14. Ya que nos indican que los residuos no son normales. De esta forma, podríamos pensar que hay posibles outliers o puntos extremos que están afectando la normalidad y la dispersión.

Podríamos considerar distintas soluciones como Verificar si hay outliers extremos y decidir si deben eliminarse o analizarse aparte o bien considerar un modelo no lineal, lo que tendr´´ia mucho sentido por lo que vimos en las gráficas. Otra opción podría ser incluir otras variables predictoras.

# Ejercicio 2
**Considera la variable respuesta crim relacionándola con el predictor medv.**
**1. Evalúa el efecto de medv sobre crim.**

```{r}

```

**2. Obtén la recta de mínimos cuadrados. Interpreta los resultados obtenidos (coeficientes, significatividad,R2, contraste del modelo, etc...).**

```{r}

```

**3. Dibuja el diagrama de dispersión, la recta de regresión y las bandas de predicción al 90 %.**

```{r}

```

**4. Realiza un análisis de los residuos.**

```{r}

```

**5. ¿Te parece adecuado haber realizado regresión lineal o es preferible otro tipo de regresión?. Ajusta el modelo que te parezca más adecuado.**

```{r}

```

# Ejercicio 3

**1. Encuentra el número óptimo de variables a incluir en un modelo predictivo de crim, según los criterios R2, BIC y CP, utilizando la metodología RegSubsets. Indica brevemente en que consiste esta metodología.**
**¿Qué variables incluye el modelo obtenido? (Seleccionar el criterio que más os guste). Interpreta los coeficientes obtenidos. ¿Tienen todas sentido?. ¿Son significativos?.**

La función RegSubsets del paquete leaps  compara de forma exhaustiva todos los subconjuntos posibles de predictores y selecciona, para cada tamaño, el mejor modelo. Después podemos elegir el modelo óptimo según un criterio (BIC, Cp, R² ajustado). Veámoslo:

```{r}
modelos <- regsubsets(crim ~ ., data = datos, nbest = 1)
res<- summary(modelos)
cat('Si utilizamos como criterio el R2, el número de componentes debe ser de ',which.max(res$adjr2))
cat('Si utilizamos como criterio el BIC, el número de componentes debe ser de ',which.min(res$bic))
cat('Si utilizamos como criterio el CP, el número de componentes debe ser de ',which.min(res$cp))

res
```
Viendo el summary, podemos decir que si nos basamos en el R2 o CP el modelo debería de incluir todas las variables. Sin embargo, si nos basamos en el BIC, el modelo estaría formado por las variables lstat,prtratio,nox,rm,chas que son las 5 más influyentes. 

En nuestro caso vamos a elegir el modelo elegido por el BIC.

```{r}
modeloBIC<-lm(crim~lstat+ptratio+nox+rm+chas,data=datos)
summary(modeloBIC)
```
Al analizar los coeficientes del modelo seleccionado por BIC, observamos que todas las variables incluidas son estadísticamente significativas (p < 0.001). Además, los predictores lstat, ptratio y nox presentan efectos positivos sobre la tasa de criminalidad, lo cual es coherente con la interpretación socioeconómica del conjunto de datos. La variable rm muestra un coeficiente positivo aunque en teoría debería relacionarse negativamente con el crimen, esto podría deberse a la colinealidad entre predictores. Por último, chas tiene signo negativo, lo que significa que hay menos criminalidad en zonas cercanas al río. Así, el modelo alcanza un R2 ajustado del 0.557, lo que indica un nivel de explicación moderado de la variabilidad de crimen.

**2. Selecciona el mejor modelo con el método stepwise. Indica brevemente en que consiste esta metodología y contesta a las siguientes preguntas:**
**¿Qué modelo piensas que es mejor? (Entre este y el/los obtenido/s mediante Regsubsets). ¿Qué% de la varianza de crim explica el modelo?¿Cuál es el efecto de la variable chas sobre crim?**

El método stepwise es una técnica de selección de variables que va construyendo el modelo añadiendo o eliminando variables paso a paso. En cada iteración evalúa si el añadir o eliminar variables mejora el modelo según un criterio (normalmente AIC). Veámoslo:

```{r}
modelocompleto <- lm(crim ~ ., data = datos)
stepwise <- step(modelocompleto, direction = "both")

summary(stepwise)
```

Si interpretamos los resultados utilizando el método stepwise en dirección ‘both’, podemos ver que usando el AIC va eliminando paso a paso las variables que menos aportan al modelo. En nuestro caso, primero se elimina la variable black y luego nox, de forma que el modelo final incluye las variables indus, chas, rm, age, dis, ptratio, lstat y medv. La mayoría de predictores resultan altamente significativos, excepto age. Este modelo presenta un R2 ajustado de 0.586, indicando un ajuste moderado, y un AIC inferior al modelo completo.

De esta forma, basándonos en el R2 ajustado, el mejor modelo es el de stepwise que explica un poco mejor la proporción de la variabilidad de crim, siendo de aproximadamente el 59%. 

Por otro lado, la variable chas tiene un efecto negativo y significativo sobre la criminalidad. Estar junto al río Charles reduce la tasa de criminalidad en aproximadamente 2.24 unidades, manteniendo constantes el resto de predictores. Esto tiene sentido, porque si buscamos que hay alrededor del río Charles podemos ver que esas áreas suelen ser más residenciales, más caras y de mayor nivel socioeconómico, lo que suele traducirse en menor criminalidad.

**3. Con el modelo obtenido con stepwise, realiza el diagnóstico de tu modelo, sin emprender ninguna acción, e indica los problemas que presenta.**

```{r}

```

**4. Emprende ahora las acciones que te parezcan oportunas e indica los problemas que has conseguido solucionar o mejorar un poco.**

```{r}

```

**5. Obtén la predicción de la tasa de criminalidad para un barrio en la mediana de los predictores en el modelo escogido. Notar que las variables categóricas se tratan de diferente manera, no hay mediana.**

```{r}

```

